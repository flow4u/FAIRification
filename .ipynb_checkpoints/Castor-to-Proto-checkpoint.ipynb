{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4eda59f8",
   "metadata": {},
   "source": [
    "# Creating a proto-dataset\n",
    "\n",
    "proto-dataset is the daily to which is added per record the base. This Jupyter Notebook is optimized for myDRE Workspace using OSDS template.\n",
    "\n",
    "Use **configuration.xlsx** to change the variables.\n",
    "\n",
    "Upload Castor export as zip to Workspace, choose as target: ./EDC.\n",
    "\n",
    "If the zip ends up in transfer (so not in ./EDC), the script will deal with it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ece2c5f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import shutil\n",
    "import glob\n",
    "import generic_functions2 as gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "93050913",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "\n",
    "file = 'CASTOR_configuration_proto.xlsx'\n",
    "sheet_name='Settings'\n",
    "settings_table = pd.read_excel(file, sheet_name=sheet_name, index_col='Item')\n",
    "\n",
    "edc_folder = settings_table.loc['edc_folder']['Value']\n",
    "proto_dataset_folder = settings_table.loc['proto_dataset_folder']['Value']\n",
    "study_name = settings_table.loc['study_name']['Value']\n",
    "recordid = settings_table.loc['recordid']['Value']\n",
    "study_daily = study_name + settings_table.loc['study_daily']['Value']\n",
    "study_base = study_name + settings_table.loc['study_base']['Value']\n",
    "separator = settings_table.loc['separator']['Value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1704b148",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./EDC/\n",
      "******************************************************************************************\n",
      "Choose source by number\n",
      "------------------------------------------------------------------------------------------\n",
      "[1]  EraCORE_csv_export_20210929\t[1]  EraCORE_csv_export_20210929\t[2]  EraCORE_csv_export_20210907\t\n",
      "[3]  EraCORE_csv_export_20210831\t\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please choose Q(uit) or between 1 and 4:  1\n"
     ]
    }
   ],
   "source": [
    "# When \n",
    "\n",
    "# move Castor zips from inbox when manually uploaded to a Workspace\n",
    "source_folders = ['z:/inbox/', 'i:/inbox/']\n",
    "# source_folder = 'z:/inbox/'\n",
    "for source_folder in source_folders:\n",
    "    try:\n",
    "        gf.move_files(study_name+'*.*', source_folder, edc_folder)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "#extract potential zip files\n",
    "gf.find_unpack_zips(edc_folder, 6)\n",
    "\n",
    "# gf.print_title('Choose the source for the Study')\n",
    "study_dir = gf.choose_dir_item(edc_folder,'folders',study_name)\n",
    "study_daily = edc_folder + study_dir + '/' + study_daily  + study_dir[-9:] + '.csv'\n",
    "study_base = edc_folder + study_dir + '/' + study_base  + study_dir[-9:] + '.csv'\n",
    "\n",
    "print('\\n'*2)\\n\n",
    "# This part is to remove unnecessary columns, this speeds up the processing considerably\n",
    "# The assumption is that what doesn't need to be mapped, isn't necessary\n",
    "print('*'*30)\n",
    "print('Please select the conversion remapping file that will be used')\n",
    "print('This will be used to identify which variables can be dropped from the source')\n",
    "conversion_excel = gf.choose_dir_item('./','files','xlsx')\n",
    "\n",
    "print('\\n'*2)\n",
    "gf.print_title('Processing, please relax and maybe grab a cup of coffee/tea ....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced27eb5-fe9e-4c98-9026-2b05d8c0609a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# creating the pandas\n",
    "df_castor_daily = pd.read_csv(study_daily, sep=separator, dtype='string')\n",
    "df_castor_base = pd.read_csv(study_base, sep=separator, dtype='string')\n",
    "\n",
    "df_castor_daily.sort_values([recordid], ascending=True, inplace=True)\n",
    "df_castor_base.sort_values([recordid], ascending=True, inplace=True)\n",
    "\n",
    "# creating list with base and daily\n",
    "study_dfs = [df_castor_daily, df_castor_base]\n",
    "\n",
    "\n",
    "# creating the list with variables that will be used\n",
    "sheet_name = 'Conversion_Table'\n",
    "index_col = 'Map_Variable'\n",
    "df_variables_mapped = pd.read_excel(conversion_excel, sheet_name=sheet_name, index_col=index_col)\n",
    "variables_used = set(df_variables_mapped.index.values.tolist())\n",
    "\n",
    "# creating the list with IDs that must be dropped\n",
    "sheet_name = 'Remove_IDs'\n",
    "index_col = 'Remove_IDs'\n",
    "df_remove_ids = pd.read_excel(conversion_excel, sheet_name=sheet_name, index_col=index_col)\n",
    "df_remove_ids.index = df_remove_ids.index.map(str)\n",
    "remove_ids = set(df_remove_ids.index.values.tolist())\n",
    "\n",
    "# remove all 'unnecessary variables'\n",
    "for df in study_dfs:\n",
    "    print(f'pre:  has dimensions {df.shape}')\n",
    "#     df = df[df.columns.intersection(variables_used)]\n",
    "    print(f'post: has dimensions {df.shape}')\n",
    "print('\\\\n'*2)\n",
    "\n",
    "# remove the IDs that must be dropped\n",
    "for df in study_dfs:\n",
    "    df = df[~df[recordid].isin(remove_ids)]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0b41995",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# remove all 'unnecessary variables'\n",
    "for df in study_dfs:\n",
    "    df.drop(columns=[col for col in df if col not in variable_used], inplace = True)\n",
    "\n",
    "# remove the IDs that must be dropped\n",
    "for df in study_dfs:\n",
    "    df = df[~df[recordid].isin(remove_ids)]\n",
    "\n",
    "# Add base to daily for eacht participant-day\n",
    "## create list of all base variables except Record Id\n",
    "base_variables = list(df_castor_base.columns)\n",
    "daily_variables = list(df_castor_daily.columns)\n",
    "\n",
    "## list with variables to remove\n",
    "remove_base_variables = [recordid, 'Unnamed: 758']\n",
    "\n",
    "## remove the variables\n",
    "base_variables = list(set(base_variables)-set(remove_base_variables))\n",
    "\n",
    "#check and if necessary rename base variable when it exists in daily\n",
    "for item in base_variables:\n",
    "    if item in daily_variables:\n",
    "        df_castor_base.rename(columns={item: 'DUB_'+item}, inplace=True)\n",
    "\n",
    "## copy df_eracore_daily to df_eracore and add base_variables to df_eracore\n",
    "df_castor = df_castor_daily.copy()\n",
    "df_castor[base_variables] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a505f9dc-6601-4422-a126-6a04b994aaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "## add base values to the right records\n",
    "def add_base_values(Id):\n",
    "    try:\n",
    "        df_castor.loc[df_castor[recordid]==Id, base_variables] = \\\n",
    "        df_castor_base.loc[df_castor_base[recordid]==Id, base_variables].values\n",
    "        return Id\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "temp = [add_base_values(Id) for Id in df_castor_base[recordid]]\n",
    "for Id in df_castor_base[recordid]:\n",
    "    add_base_values(Id)\n",
    "\n",
    "\n",
    "## remove base and daily from memory\n",
    "del df_castor_daily\n",
    "del df_castor_base\n",
    "del study_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d216feca",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved: ./proto-Castor/Proto-Castor.csv\n",
      "\n",
      "\n",
      "\n",
      "******************************************************************************************\n",
      "Finished creating Proto-EraCORE\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Saving the prot-Castor both as .sx.sx as csv\n",
    "output_path = './proto-dataset'\n",
    "df_castor.to_excel(output_path+ '/proto-dataset.xlsx', index=False)\n",
    "gf.output_csv(df_castor, output_path+'/proto-dataset', False)\n",
    "\n",
    "input('Enter to continue....')\n",
    "print('\\n'*2)\n",
    "gf.print_title('Finished creating Proto-'+study_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c21f431b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
