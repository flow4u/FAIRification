{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "37ce4aed",
   "metadata": {},
   "source": [
    "# Remapping a dataset\n",
    "\n",
    "Run to execute\n",
    "Use Restart to run again\n",
    "\n",
    "You'll be asked to select an Excel file that contains the mapping and configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a3bf51ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run to execute, use Restart to run again\n",
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import generic_functions2 as gf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9723aab7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "******************************************************************************************\n",
      "Select the Excel containing all the configuration & mapping\n",
      "------------------------------------------------------------------------------------------\n",
      "******************************************************************************************\n",
      "Choose source by number\n",
      "------------------------------------------------------------------------------------------\n",
      "[1]  conversion_remapping.xlsx\t[2]  configuration_scramble.xlsx\t[3]  configuration_proto.xlsx\t\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please choose Q(uit) or between 1 and 3:  1\n"
     ]
    }
   ],
   "source": [
    "# select the conversion.xslx\n",
    "folder = './'\n",
    "print('\\n'*2)\n",
    "gf.print_title('Select the Excel containing all the configuration & mapping')\n",
    "conversion_excel = gf.choose_dir_item(folder,'files', 'xlsx')\n",
    "\n",
    "print('\\n'*2)\n",
    "gf.print_title('Processing, please relax and maybe grab a cup of coffee/tea ....')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3664f20f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read converstion table\n",
    "# conversion_excel = 'conversion.xlsx'\n",
    "sheet_name='Conversion_Table'\n",
    "conversion_table = pd.read_excel(conversion_excel, sheet_name=sheet_name, index_col=None)\n",
    "sheet_name='Key_Table'\n",
    "key_table = pd.read_excel(conversion_excel, sheet_name=sheet_name, index_col='Key_Old', converters = {'New_Key': str, 'Old_Key': str})\n",
    "sheet_name='Settings'\n",
    "settings_table = pd.read_excel(conversion_excel, sheet_name=sheet_name, index_col='Item')\n",
    "\n",
    "# these variables will be deleted from the dataset typical use case is temporary variables\n",
    "item = 'DropVariables'\n",
    "df_temp = pd.read_excel(conversion_excel, sheet_name=item) #, index_col=item)\n",
    "drop_variables = df_temp[item].values.tolist()\n",
    "\n",
    "\n",
    "# creating the list with IDs that must be dropped\n",
    "sheet_name = 'Remove_IDs'\n",
    "index_col = 'Remove_IDs'\n",
    "df_remove_ids = pd.read_excel(conversion_excel, sheet_name=sheet_name, index_col=index_col)\n",
    "df_remove_ids.index = df_remove_ids.index.map(str)\n",
    "remove_ids = set(df_remove_ids.index.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dfc70aa5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# read settings\n",
    "source_dir = settings_table.loc[\"source_dir\"][\"Variable\"]\n",
    "converted_dir = settings_table.loc[\"converted_dir\"][\"Variable\"]\n",
    "source_file = settings_table.loc[\"source_filename\"][\"Variable\"]\n",
    "source_separator = settings_table.loc[\"source_separator\"][\"Variable\"]\n",
    "converted_file = settings_table.loc[\"converted_filename\"][\"Variable\"]\n",
    "converted_separator = settings_table.loc[\"converted_separator\"][\"Variable\"]\n",
    "\n",
    "# read data\n",
    "df = pd.read_csv(source_dir + '/' + source_file, index_col=None, low_memory=False, keep_default_na=False, dtype=\"string\")\n",
    "source_variables = df.columns\n",
    "\n",
    "# remove the IDs that must be dropped\n",
    "df = df[~df[recordid].isin(remove_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "342733ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# keep track of all the variables that are mapped\n",
    "mapped_variables = []\n",
    "\n",
    "# keep track of all the errors\n",
    "errors = []\n",
    "\n",
    "# go through the conversion table to make the changes\n",
    "for row in conversion_table.iterrows():\n",
    "    # reading the necessary variables\n",
    "    nv = row[1]['New_Variable']\n",
    "    toc = row[1]['TypeOfConversion']\n",
    "    mv = row[1]['Map_Variable']\n",
    "    con = row[1]['Conversion']\n",
    "    mapped_variables.append(mv)\n",
    "    \n",
    "\n",
    "    if mv == mv: # or mv not in df.columns:\n",
    "        # convert the conversion to a dictionary\n",
    "        if con == con and str(con)[0] == \"{\":\n",
    "            con.replace(\"'\",'\"')\n",
    "            res = json.loads(con)\n",
    "\n",
    "        # convert to lower case just in case of typo\n",
    "        conversion_type = str(toc).lower()\n",
    "        \n",
    "        # swapping the variables\n",
    "        if conversion_type == 'swap':\n",
    "            # add nv to mapped_variables otherwise it causes a false negative\n",
    "            mapped_variables.append(nv)\n",
    "            # swapping the column names\n",
    "            df.rename(columns={nv: 'mv', mv: 'nv'}, inplace=True)\n",
    "            df.rename(columns={'mv': mv, 'nv': nv}, inplace=True)\n",
    "            \n",
    "        # converting dates\n",
    "        if conversion_type == 'date':\n",
    "            try:\n",
    "                df[nv] = df.apply(lambda x: gf.correct_date(x[mv], con), axis=1)\n",
    "            except:\n",
    "                errors.append(f'Error with nv:{nv}, mv:{mv} in conversion: {conversion_type}')\n",
    "        \n",
    "        # adding variables\n",
    "        if conversion_type == 'add':\n",
    "            try:\n",
    "                items = con.replace(' ','').split(',')\n",
    "                for x, item in enumerate(items):\n",
    "                    df[item].replace(np.nan, '0', regex=True, inplace=True)\n",
    "                    if x == 0:\n",
    "                        df[nv] = df[item].astype(int)\n",
    "                    else:\n",
    "                        df[nv] += df[item].astype(int)\n",
    "                df[nv] = df[nv].replace(0, '')\n",
    "            except:\n",
    "                errors.append(f'Error with nv:{nv}, mv:{mv} in conversion: {conversion_type}')\n",
    "        \n",
    "        # copying variables\n",
    "        if conversion_type == 'copy':\n",
    "            try:\n",
    "                df[nv] = df[mv]\n",
    "            except:\n",
    "                errors.append(f'Error with nv:{nv}, mv:{mv} in conversion: {conversion_type}')\n",
    "        \n",
    "        # duration in days\n",
    "        if conversion_type == 'duration':\n",
    "            try:\n",
    "                df[nv] = df.apply(lambda x: gf.duration_days(x, con), axis=1)\n",
    "            except:\n",
    "                errors.append(f'Error with nv:{nv}, mv:{mv} in conversion: {conversion_type}')\n",
    "            \n",
    "        # normal variable swapping with value conversion\n",
    "        if conversion_type == \"normal\":\n",
    "            if mv in df:\n",
    "                df = df.rename(columns={mv: nv})\n",
    "                # convert values if con is not empty\n",
    "                if con == con:\n",
    "                    # make sure if a value is missed, that it is visible\n",
    "                    df[nv] = df[nv].map(res).fillna(\"\")\n",
    "            else:\n",
    "                df[nv] = 'variable not in source'\n",
    "\n",
    "        if conversion_type == \"check2option\" and con == con:\n",
    "            # create empty list of all the checkbox variables\n",
    "            subcolumns = []\n",
    "            for key, value in res.items():\n",
    "                checkbox = mv + \"#\" + key\n",
    "                subcolumns.append(checkbox)\n",
    "                # assign right value to the checkbox column\n",
    "                df[checkbox] = df[checkbox].map({1: value})\n",
    "            # join the checkbox columns into target column\n",
    "            df[nv] = df[subcolumns].apply(\n",
    "                lambda x: \",\".join(x.dropna().astype(str)), axis=1\n",
    "            )\n",
    "            # remmve all the check box columns\n",
    "            df.drop(subcolumns, axis=1, inplace=True)\n",
    "\n",
    "        # convesion of options to checkbox format\n",
    "        if conversion_type == \"option2check\" and con == con:\n",
    "            # convert dtype of target because dictionary expects a string\n",
    "            df[mv] = df[mv].astype(\"string\")\n",
    "            # counter is a counter that keeps track of the value to be expected\n",
    "            counter = 1\n",
    "            # create the checkbox variable and add the value '1' if applicable\n",
    "            for key, value in res.items():\n",
    "                # new checkbox variable\n",
    "#                 prior to: 2021-12-30\n",
    "#                 checkbox = nv + \"#\" + value\n",
    "                checkbox = value\n",
    "                # add the values of the old variable\n",
    "                df[checkbox] = df[mv]\n",
    "                # add the value '1' if correct, leave empty otherwise\n",
    "                df[checkbox] = df[checkbox].map({str(counter): \"1\"}).fillna(\"\")\n",
    "                counter += 1\n",
    "#             # delete the old column\n",
    "#             prior to: 2021-12-30 ....the variable can be removed using DropVariables in conversion_remapping.xlsx\n",
    "#             del df[mv]\n",
    "\n",
    "        # adding units\n",
    "        if conversion_type == \"unit\":\n",
    "            if mv in df:\n",
    "                # copy the values\n",
    "                df[nv] = df[mv]\n",
    "                # add the units when not empty\n",
    "                if df[nv].dtype == \"O\":\n",
    "                    df.loc[df[nv] != \"\", nv] = str(con)\n",
    "                else:\n",
    "                    df.loc[df[nv].notnull(), nv] = str(con)\n",
    "                    df[nv].replace(np.nan, \"\", regex=True, inplace=True)\n",
    "                \n",
    "        # multiply\n",
    "        if conversion_type == \"multiply\":\n",
    "            try:\n",
    "                df[mv] = pd.to_numeric(df[mv])\n",
    "                df[nv] = df[mv] * float(con)\n",
    "            except:\n",
    "                errors.append(f'Error with nv:{nv}, mv:{mv} in conversion: {conversion_type}')\n",
    "                \n",
    "        # replacing keys\n",
    "        if conversion_type == \"id\":\n",
    "            # crelate list with missing keys\n",
    "            id_set = list(set(df[mv]))\n",
    "            df_missing_keys = pd.DataFrame({'MissingKeys': [x for x in id_set if x not in list(key_table.index)]})\n",
    "            # copy the values\n",
    "            df[nv] = df[mv]\n",
    "            # convert key_table into dictionary\n",
    "            res = key_table.to_dict(\"dict\")\n",
    "            res = {str(key): str(value) for key, value in res[\"Key_New\"].items()}\n",
    "            df[nv] = df[nv].astype(\"string\")\n",
    "            # make sure if a value is missed, that it is visible\n",
    "            df[nv] = df[nv].map(res).fillna(\"mapping missing\")\n",
    "            \n",
    "        # copy to defrag\n",
    "        df = df.copy()\n",
    "\n",
    "# creating list with empty variables\n",
    "df_empty = pd.DataFrame({'VarsWithoutValues': [x for x in df.columns if df[x].empty]})\n",
    "\n",
    "# creating list with non-maped variables\n",
    "df_non_mapped = pd.DataFrame({'NonMappedVars': [x for x in source_variables if x not in mapped_variables]})\n",
    "\n",
    "# creating list with errors\n",
    "df_errors = pd.DataFrame({'Errors': [x for x in errors]})\n",
    "\n",
    "# remove the variables in DropVariables\n",
    "for item in drop_variables:\n",
    "    try:\n",
    "        del df[item]\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Setting the correct order, repeating the loop, but easier and more robust to do it here\n",
    "# ordered list of columns\n",
    "column_order = []\n",
    "for row in conversion_table.iterrows():\n",
    "    # reading the necessary variables\n",
    "    nv = row[1][\"New_Variable\"]\n",
    "    toc = row[1][\"TypeOfConversion\"]\n",
    "    con = row[1][\"Conversion\"]\n",
    "    conversion_type = str(toc).lower()\n",
    "    if nv not in df.columns and conversion_type != 'option2check':\n",
    "        df[nv] = ''\n",
    "        column_order.append(nv)\n",
    "    elif con == con and str(con)[0] =='{' and conversion_type=='option2check':\n",
    "        res = json.loads(con)\n",
    "        for key, value in res.items():\n",
    "            # new checkbox variable\n",
    "#             prior to 2021-12-30\n",
    "#             checkbox = nv + \"#\" + value\n",
    "            checkbox = value\n",
    "            column_order.append(checkbox)\n",
    "    else:\n",
    "        column_order.append(nv)\n",
    "\n",
    "df=df[column_order]            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffa40811",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter to coninue.... \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "******************************************************************************************\n",
      "All done, the output (cSV and Excel) can be found timestamped in: ./Converted\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "## write converted data\n",
    "stamp = f'{datetime.now():%Y%m%d-%H%M%S}'\n",
    "file_name = converted_dir + f\"/{stamp}_\" + converted_file\n",
    "df.to_csv(file_name + \".csv\", sep=converted_separator, index=False)\n",
    "df.to_excel(file_name + \".xlsx\", index=False)\n",
    "file_name = converted_dir + f\"/{stamp}_\" + converted_file + '_EMPTY'\n",
    "df_empty.to_csv(file_name + \".csv\", sep=converted_separator, index=False)\n",
    "file_name = converted_dir + f\"/{stamp}_\" + converted_file + '_NON_MAPPED'\n",
    "df_non_mapped.to_csv(file_name + \".csv\", sep=converted_separator, index=False)\n",
    "\n",
    "# not always there will be Id conversion\n",
    "try:\n",
    "    file_name = converted_dir + f\"/{stamp}_\" + converted_file + '_MISSING_KEYS'\n",
    "    df_missing_keys.to_csv(file_name + \".csv\", sep=converted_separator, index=False)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# not always there will be errors\n",
    "try:\n",
    "    file_name = converted_dir + f\"/{stamp}_\" + converted_file + '_ERRORS'\n",
    "    df_errors.to_csv(file_name + \".csv\", sep=converted_separator, index=False)\n",
    "except:\n",
    "    pass\n",
    "\n",
    "input('Enter to continue....')\n",
    "print('\\n'*2)\n",
    "gf.print_title(\n",
    "    f\"All done, the output (CSV and Excel) can be found timestamped in: {converted_dir}\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
